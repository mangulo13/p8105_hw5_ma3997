---
title: "Homework 5 "
output: github_document
---

```{r setup}
library(tidyverse)
library(rvest)
library(ggplot2)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)


theme_set(theme_minimal()+theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colur = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

Hello! And welcome to my solutions for Homework 5. Enjoy.

## Problem 1

Read in the data. 

```{r}
homicide_df = 
  read_csv("./data/homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")

```

Let's look at this a bit. 

```{r}
aggregrate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  ) 
```


Can I do a prop test for a single city?

```{r}
prop.test(
  aggregrate_df %>% filter(city_state =="Baltimore_MD") %>% pull(hom_unsolved), 
  aggregrate_df %>% filter(city_state =="Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

R spits out statistical info in a format that's hard to extract. Broom::tidy gives that info in a nice tibble

Try to iterate.....

```{r}
results_df = 
  aggregrate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~ prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Map2 lets you map over two elements at the same time 

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate))+
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```


```{r, error = TRUE}
city_prop_test = function(df) {
  
  n_unsolved...
  n_total...
  prop.test(...)
}

homicide_df = 
  read_csv("./data/homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)


```



## Problem 2

```{r}
path_df = 
  tibble(
    path = list.files("data/lda_data")
    ) %>% 
  mutate(
    subject = path,
    path = str_c("data/lda_data/", path),
    data = map(path, read_csv)
    ) %>% 
  unnest(data) 

tidy_df = 
  path_df %>% 
  select(-path) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "obs"
  ) %>% 
  separate(subject, into = c("group", "id")) %>% 
  view()

tidy_df %>% 
  ggplot(aes(x = week, y = obs, group = id, color = id))+
  geom_line()+
  facet_grid(. ~ group)

```

The experimental arm seems to have a positive trend over the course of the weeks while the control arm seems to generally stay the same. 


## Question 3

```{r}
sim_function = function( samp_size = 30, mu = 0, sigma = 5) {
  
  sim_df = 
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma))
  
  sim_df %>% 
    summarize(
      mu = mean(x),
      sigma = sd(x)
    ) 
  
  sim_df %>% 
    t.test() %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
  
} 

means = c(1:6)
  


output = vector("list", length = 6)

for (i in 1:6) {
  
  output[[i]] = rerun(5000, sim_function(mu = means[[i]])) %>% 
    bind_rows()
}



sim_df = 
  tibble(
    means = means
  ) %>% 
  mutate(estimates = output) %>% 
  unnest(estimates) %>% 
  mutate(reject = ifelse(p.value < 0.05, 1, 0)) 
  


plot1 = 
  sim_df %>% 
  group_by(means)%>% 
  summarize(
    total_tests = n(),
    reject_tests = sum(reject)
    ) %>% 
  mutate(power = reject_tests/total_tests)%>% 
  ggplot(aes(x = means, y = power))+
  geom_point()



plot2 = 
  sim_df %>% 
  group_by(means) %>% 
  summarize(avg_estimate = mean(estimate)) %>% 
  ggplot(aes(x = means, y = avg_estimate))+
  geom_point()

plot3 = 
  sim_df %>% 
  filter(reject == 1) %>% 
  group_by(means) %>% 
  summarize(avg_estimate = mean(estimate)) %>% 
  ggplot(aes(x = means, y = avg_estimate))+
  geom_point()


```

```{r}
plot1
```

As effect sizes increase, power significantly increases. 

```{r}
plot2
plot3
```

The sample means are approximately equal to the true mean which is as expected given the large sample size. Filtering by estimates that are statistically significant provides estimates that are also approximately equal to the true means which also makes sense since we are only viewing sample means that are not equal to zero. 



















